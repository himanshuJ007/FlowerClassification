{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def show_image(path):\n",
    "    img = Image.open(path)\n",
    "    img_arr = np.array(img)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(np.transpose(img_arr, (0, 1, 2)))\n",
    "    \n",
    "    \n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "transformations = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "total_dataset = datasets.ImageFolder(\"flowers\", transform = transformations)\n",
    "dataset_loader = DataLoader(dataset = total_dataset, batch_size = 100)\n",
    "items = iter(dataset_loader)\n",
    "image, label = items.next()\n",
    "\n",
    "\n",
    "def show_transformed_image(image):\n",
    "    np_image = image.numpy()\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(np.transpose(np_image, (1, 2, 0)))\n",
    "    \n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.8 * len(total_dataset))\n",
    "test_size = len(total_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(total_dataset, [train_size, test_size])\n",
    "\n",
    "train_dataset_loader = DataLoader(dataset = train_dataset, batch_size = 100)\n",
    "test_dataset_loader = DataLoader(dataset = test_dataset, batch_size = 100)\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class FlowerClassifierCNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=5):\n",
    "        super(FlowerClassifierCNNModel,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3,stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.lf = nn.Linear(in_features=32 * 32 * 24, out_features=num_classes)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = self.conv1(input)\n",
    "        output = self.relu1(output)\n",
    "        \n",
    "        output = self.maxpool1(output)\n",
    "        \n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "        \n",
    "        output = output.view(-1, 32 * 32 * 24)\n",
    "\n",
    "        output = self.lf(output)\n",
    "\n",
    "        return output\n",
    "    \n",
    "from torch.optim import Adam\n",
    "\n",
    "cnn_model = FlowerClassifierCNNModel()\n",
    "cnn_model.to(device)\n",
    "optimizer = Adam(cnn_model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# cnn_model = FlowerClassifierCNNModel()\n",
    "# cnn_model.load_state_dict(torch.load('flowermodel'))\n",
    "# cnn_model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "def getImageClassName(sdfds):\n",
    "    test_image = Image.open(sdfds)\n",
    "    test_image_tensor = transformations(test_image).float()\n",
    "    test_image_tensor = test_image_tensor.unsqueeze_(0)\n",
    "    test_image_tensor = test_image_tensor.to(device)\n",
    "    output = cnn_model(test_image_tensor)\n",
    "    output.data.cpu().numpy().argmax()\n",
    "    return total_dataset.classes[output.data.cpu().numpy().argmax()].capitalize()\n",
    "\n",
    "\n",
    "\n",
    "def train_and_build(n_epoches):\n",
    "    tl=0\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for epoch in range(n_epoches):\n",
    "        cnn_model.train()\n",
    "        for i, data in enumerate(train_dataset_loader):\n",
    "            (images, labels) = data[0].to(device),data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = cnn_model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss = loss.item()\n",
    "            tl+=running_loss\n",
    "            if i % 10 == 0:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss))\n",
    "        x.append(epoch)\n",
    "        y.append(tl)\n",
    "        tl=0\n",
    "        plt.plot(x, y)\n",
    "        \n",
    "        \n",
    "\n",
    "cnn_model.eval()\n",
    "cnn_model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "def get_vector(image_name):\n",
    "    # 1. Load the image with Pillow library\n",
    "    \n",
    "    test_image = Image.open(image_name)\n",
    "    test_image_tensor = transformations(test_image).float()\n",
    "    test_image_tensor = test_image_tensor.unsqueeze_(0)\n",
    "    test_image_tensor = test_image_tensor.to(device)\n",
    "\n",
    "    t_img = test_image_tensor\n",
    "    \n",
    "    df = cnn_model(t_img)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def getCosSimi(pic_one_vector,pic_two_vector):\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    cos_sim = cos(pic_one_vector,\n",
    "                  pic_two_vector)\n",
    "    return cos_sim.tolist()[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getListOfSlrImges(chooseImage):\n",
    "    pic_one_vector = get_vector(chooseImage)\n",
    "\n",
    "    listOfImages = []\n",
    "\n",
    "    for folder in os.listdir('flowers'):\n",
    "        for filename in os.listdir(os.path.join('flowers', folder)):\n",
    "            pic_two_vector = get_vector(os.path.join('flowers', folder,filename) )\n",
    "            #print(os.path.join('flowers', folder,filename))\n",
    "            if getCosSimi(pic_one_vector,pic_two_vector) > 0.98:\n",
    "                listOfImages.append((os.path.join('flowers', folder,filename)))\n",
    "    return listOfImages\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'flowers\\\\sunflower\\\\44079668_34dfee3da1_n.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b4117a3598d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetImageClassName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'flowers\\\\sunflower\\\\44079668_34dfee3da1_n.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# getListOfSlrImges( 'flowers\\\\sunflower\\\\44079668_34dfee3da1_n.jpg')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5ed4b8287261>\u001b[0m in \u001b[0;36mgetImageClassName\u001b[0;34m(sdfds)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetImageClassName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdfds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdfds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0mtest_image_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mtest_image_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_image_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2547\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2548\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2549\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'flowers\\\\sunflower\\\\44079668_34dfee3da1_n.jpg'"
     ]
    }
   ],
   "source": [
    "getImageClassName('flowers\\\\sunflower\\\\44079668_34dfee3da1_n.jpg')\n",
    "# getListOfSlrImges( 'flowers\\\\sunflower\\\\44079668_34dfee3da1_n.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'flower_sample/568715474_bdb64ccc32.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-758f77fb32e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0mcontent_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"flower_sample/568715474_bdb64ccc32.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0mresized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontent_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mANTIALIAS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2547\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2548\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2549\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'flower_sample/568715474_bdb64ccc32.jpg'"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "from tkinter.ttk import *\n",
    "import tkinter.messagebox as messagebox\n",
    "from PIL import ImageTk, Image\n",
    "import os\n",
    "\n",
    "#from tkinter.filedialog import askopenfilename,ask\n",
    "\n",
    "\n",
    "window = Tk()\n",
    "window.title(\"Welcome to Neural Style Transfer\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# image = PhotoImage(file=\"intro.gif\")\n",
    "# label = Label(image=image)\n",
    "# label.grid(row=0,column=0)\n",
    "\n",
    "\n",
    "def selectContentFile():\n",
    "    filename = filedialog.askopenfilename(initialdir='C:/Users/ashish/Machine Learning Noida')\n",
    "    if filename != \"\":\n",
    "        if filename.endswith('jpg') or filename.endswith('jpeg') or filename.endswith('png'):\n",
    "            txt.delete(0,END)\n",
    "            txt.insert(0,filename)   \n",
    "            \n",
    "            \n",
    "            content_image = Image.open(txt.get())\n",
    "            resized = content_image.resize(( int(content_image.width*0.75), int(content_image.height*0.75) ), Image.ANTIALIAS)\n",
    "            content_photo = ImageTk.PhotoImage(resized)\n",
    "            content_label.configure(image=content_photo)\n",
    "#             content_label = Label(image=content_photo)\n",
    "            content_label.image = content_photo # keep a reference!\n",
    "            content_label.grid(row =1, column =1,pady=(20,20))\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "def applyStyle():\n",
    "    \n",
    "    \n",
    "    if(txt.get()=='' ):\n",
    "        messagebox.showerror(\"Error\", \"Please Fill All the Boxes\")\n",
    "    else:\n",
    "        sdf = getImageClassName(txt.get())\n",
    "        sdf = 'It is a '+sdf\n",
    "        lbl2.config(text=sdf)\n",
    "        lis = getListOfSlrImges(txt.get())\n",
    "        lis = lis[:6]\n",
    "        COLUMNS = 3\n",
    "        image_count = 0\n",
    "        for infile in lis:\n",
    "            infile.replace(\"\\\\\",\"/\")\n",
    "            print(infile)\n",
    "            if infile in txt.get():\n",
    "                continue\n",
    "            image_count += 1\n",
    "            r, c = divmod(image_count-1, COLUMNS)\n",
    "            im = Image.open(infile )\n",
    "            im = im.resize((150,150))\n",
    "            cp = ImageTk.PhotoImage(im)\n",
    "            cl = Label(image=cp)\n",
    "            cl.image = cp # keep a reference!\n",
    "            cl.grid(row=r+5, column=c)\n",
    "            r=r+1\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#Selecting the content image\n",
    "            \n",
    "lbl = Label(window, text=\" Your Content Image: \")\n",
    "lbl.grid(column=0, row=0,pady=(5,6))\n",
    "\n",
    "txt = Entry(window,width=75)\n",
    "txt.grid(column=1, row=0,pady=(5,6))\n",
    "\n",
    "\n",
    "btn = Button(window, text=\"Select File\", command=selectContentFile)\n",
    "btn.grid(column=2, row=0, padx=(10,10))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# bg=\"#51CCE0\",fg=\"#FFFFFF\",font=(\"Arial Bold\", 13),\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "\n",
    "\n",
    "content_image = Image.open(\"flower_sample/568715474_bdb64ccc32.jpg\")\n",
    "resized = content_image.resize(( int(content_image.width*0.75), int(content_image.height*0.75) ), Image.ANTIALIAS)\n",
    "\n",
    "content_photo = ImageTk.PhotoImage(resized)\n",
    "content_label = Label(image=content_photo)\n",
    "content_label.image = content_photo # keep a reference!\n",
    "content_label.grid(row =1, column =1,pady=(20,20))\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "# img = ImageTk.PhotoImage(Image.open(\"images_tkinter/udnie.gif\"))\n",
    "# panel = Label(window, image = img)\n",
    "# panel.grid(row=4,column=1)\n",
    "\n",
    "# on change dropdown value\n",
    "\n",
    "        \n",
    "    \n",
    "btn2 = Button(window, text=\"Apply\", command=applyStyle)\n",
    "btn2.grid(column=1, row=2)\n",
    "\n",
    "lbl2 = Label(window, text=\"\")\n",
    "lbl2.grid(column=1, row=3,pady=(20,20))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b26a47049605>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnn_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cnn_model' is not defined"
     ]
    }
   ],
   "source": [
    "cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
